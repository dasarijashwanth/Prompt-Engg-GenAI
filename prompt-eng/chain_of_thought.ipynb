{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: {'model': 'Llama-3.2-3B-Instruct', 'messages': [{'role': 'user', 'content': '\\nYou are an AI that generates a comprehensive project report using chain-of-thought reasoning.\\nFirst, reason internally about the best way to describe:\\n1) Project Overview (Title, Goal, Problem Statement, Key Objectives, Scope)\\n2) Data & Methodologies (Data Sources, Data Processing, Methodology, Approach)\\n\\nThen, provide a detailed final answer in Markdown:\\n- Use multiple paragraphs and headings.\\n- Expand on each point with descriptive explanations.\\n- Use subheadings if necessary to organize information.\\n\\n[START OF INSTRUCTIONS]\\nProject Details:\\n- Title: \"Advanced Image Recognition\"\\n- Goal: \"Achieve 95% accuracy on a custom image dataset\"\\n- Problem Statement: \"Manual image labeling is slow and error-prone\"\\n- Key Objectives:\\n  1) Develop a robust CNN model\\n  2) Implement automated data augmentation\\n- Scope: \"Focus on large-scale image datasets\"\\n\\nData & Methodologies:\\n- Data Sources: \"Proprietary image dataset + open-source augmentation libraries\"\\n- Data Processing: \"Image normalization, labeling, and augmentation pipeline\"\\n- Methodology: \"Convolutional Neural Networks, transfer learning\"\\n- Approach: \"Iterative training with real-time validation\"\\n\\nInstructions:\\n1) Think step-by-step internally about how to structure and expand these sections.\\n2) Present only the final output in Markdown, using multiple paragraphs, bullet points, or subheadings as needed.\\n3) Aim for a thorough, descriptive style.\\n[END OF INSTRUCTIONS]\\n'}]}\n",
      "===== CHAIN-OF-THOUGHT OUTPUT (PROJECT OVERVIEW + DATA & METHODOLOGIES) =====\n",
      "**Chain-of-Thought Reasoning Process**\n",
      "\n",
      "Upon internal reflection, I determine that the project report structure should be hierarchical and easy to navigate. To achieve this, I allocate the following sections:\n",
      "\n",
      "1. **Project Overview**: This section should provide a concise introduction to the project, highlighting its significance, objectives, and scope. It should address the problem statement, provide context, and set the tone for the report.\n",
      "2. **Data & Methodologies**: This section should delve into the specifics of the project's data and methodology, including data sources, processing, and approaches. It should justify the chosen methodology and explain how it will be implemented.\n",
      "\n",
      "**Project Overview**\n",
      "\n",
      "Advanced Image Recognition Project\n",
      "================================\n",
      "\n",
      "### Title and Goal\n",
      "\n",
      "The Advanced Image Recognition project aims to achieve 95% accuracy on a custom image dataset by developing a robust Convolutional Neural Network (CNN) model.\n",
      "\n",
      "### Problem Statement\n",
      "\n",
      "Manual image labeling is a slow and error-prone process, which hampers the efficient use of large-scale image datasets. Developing an automated labeling system is essential to overcome this limitation.\n",
      "\n",
      "### Key Objectives\n",
      "\n",
      "The key objectives of this project are:\n",
      "\n",
      "*   Develop a robust CNN model that can achieve high accuracy on the custom image dataset.\n",
      "*   Implement automated data augmentation to increase the size and diversity of the training dataset.\n",
      "\n",
      "### Scope\n",
      "\n",
      "The focus of this project is on large-scale image datasets, which require efficient processing and labeling techniques.\n",
      "\n",
      "**Data & Methodologies**\n",
      "\n",
      "Data and Methodologies\n",
      "---------------------\n",
      "\n",
      "### Data Sources\n",
      "\n",
      "The project will utilize a proprietary image dataset and open-source augmentation libraries to generate additional training data.\n",
      "\n",
      "*   **Proprietary Image Dataset**: The proprietary image dataset will serve as the primary training dataset. This dataset will be carefully curated to ensure it is representative of the target application.\n",
      "*   **Open-Source Augmentation Libraries**: Open-source libraries, such as OpenCV and TensorFlow, will be used to generate additional training data through data augmentation techniques.\n",
      "\n",
      "### Data Processing\n",
      "\n",
      "The data processing pipeline will involve the following steps:\n",
      "\n",
      "1.  **Image Normalization**: Images will be normalized to normalize pixel values and reduce the impact of scaling differences between training images.\n",
      "2.  **Labeling**: The image dataset will be labeled using a custom annotation tool to ensure consistency and accuracy.\n",
      "3.  **Data Augmentation**: Data augmentation techniques, such as rotation, scaling, and flipping, will be applied to generate additional training data.\n",
      "\n",
      "### Methodology\n",
      "\n",
      "The project will employ a CNN-based approach to achieve high accuracy on the custom image dataset.\n",
      "\n",
      "*   **Convolutional Neural Networks**: CNNs are a type of neural network specifically designed for image processing tasks. They are well-suited for image recognition tasks due to their ability to extract features from images.\n",
      "*   **Transfer Learning**: Transfer learning refers to the process of using a pre-trained model as a starting point for a new task. This approach can significantly reduce the training time and improve the accuracy of the model.\n",
      "\n",
      "### Approach\n",
      "\n",
      "The approach to implementing the project will be iterative, involving the following steps:\n",
      "\n",
      "1.  **Model Development**: The CNN model will be developed using a pre-trained architecture, and fine-tuned for the specific task.\n",
      "2.  **Real-Time Validation**: The model will be trained on a validation dataset to monitor its performance and gather insights on areas for improvement.\n",
      "3.  **Rule-Based Iteration**: Based on the validation results, adjustments will be made to the model architecture and hyperparameters to optimize its performance.\n",
      "\n",
      "By following this approach, the project aims to achieve state-of-the-art performance on the custom image dataset.\n",
      "\n",
      "Time taken: 5.613s\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "## CHAIN-OF-THOUGHT PROMPTING: PROJECT OVERVIEW + DATA & METHODOLOGIES\n",
    "############################################################\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# 1) Define a more detailed Chain-of-Thought prompt\n",
    "COT_PROMPT = \"\"\"\n",
    "You are an AI that generates a comprehensive project report using chain-of-thought reasoning.\n",
    "First, reason internally about the best way to describe:\n",
    "1) Project Overview (Title, Goal, Problem Statement, Key Objectives, Scope)\n",
    "2) Data & Methodologies (Data Sources, Data Processing, Methodology, Approach)\n",
    "\n",
    "Then, provide a detailed final answer in Markdown:\n",
    "- Use multiple paragraphs and headings.\n",
    "- Expand on each point with descriptive explanations.\n",
    "- Use subheadings if necessary to organize information.\n",
    "\n",
    "[START OF INSTRUCTIONS]\n",
    "Project Details:\n",
    "- Title: \"Advanced Image Recognition\"\n",
    "- Goal: \"Achieve 95% accuracy on a custom image dataset\"\n",
    "- Problem Statement: \"Manual image labeling is slow and error-prone\"\n",
    "- Key Objectives:\n",
    "  1) Develop a robust CNN model\n",
    "  2) Implement automated data augmentation\n",
    "- Scope: \"Focus on large-scale image datasets\"\n",
    "\n",
    "Data & Methodologies:\n",
    "- Data Sources: \"Proprietary image dataset + open-source augmentation libraries\"\n",
    "- Data Processing: \"Image normalization, labeling, and augmentation pipeline\"\n",
    "- Methodology: \"Convolutional Neural Networks, transfer learning\"\n",
    "- Approach: \"Iterative training with real-time validation\"\n",
    "\n",
    "Instructions:\n",
    "1) Think step-by-step internally about how to structure and expand these sections.\n",
    "2) Present only the final output in Markdown, using multiple paragraphs, bullet points, or subheadings as needed.\n",
    "3) Aim for a thorough, descriptive style.\n",
    "[END OF INSTRUCTIONS]\n",
    "\"\"\"\n",
    "\n",
    "# 2) Create a payload with moderate token usage\n",
    "payload_cot = create_payload(\n",
    "    target=\"open-webui\",\n",
    "    model=\"Llama-3.2-3B-Instruct\",  # Updated model\n",
    "    prompt=COT_PROMPT,\n",
    "    temperature=0.8,                # Slightly higher to encourage more detailed text\n",
    "    num_ctx=300,                    # Increase context for longer expansions\n",
    "    num_predict=400                 # Enough tokens for detailed paragraphs\n",
    ")\n",
    "\n",
    "def request_with_retry(payload, max_retries=2, delay=3):\n",
    "    \"\"\"\n",
    "    Attempts the model_req call up to `max_retries` times,\n",
    "    waiting `delay` seconds between tries if a 504 error occurs.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            time_cot, cot_output = model_req(payload=payload)\n",
    "            return time_cot, cot_output\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"504\" in error_str or \"Bad Gateway\" in error_str:\n",
    "                print(f\"Got 504 error. Retrying in {delay} seconds...\")\n",
    "                attempt += 1\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                # Different error; re-raise\n",
    "                raise e\n",
    "    raise RuntimeError(\"Max retries reached. 504 error persists.\")\n",
    "\n",
    "# 3) Execute the chain-of-thought request with retries\n",
    "time_cot, cot_output = request_with_retry(payload_cot)\n",
    "\n",
    "# 4) Print the final Markdown output\n",
    "print(\"===== CHAIN-OF-THOUGHT OUTPUT (PROJECT OVERVIEW + DATA & METHODOLOGIES) =====\")\n",
    "print(cot_output)\n",
    "if time_cot:\n",
    "    print(f\"\\nTime taken: {time_cot}s\")\n",
    "\n",
    "# 5) (Optional) Log the result for future reference\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "log_entry = [\n",
    "    datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"chain_of_thought_data_methods\",\n",
    "    \"Llama-3.2-3B-Instruct\",\n",
    "    0.8,\n",
    "    time_cot,\n",
    "    cot_output.replace(\"\\n\", \"\\\\n\")\n",
    "]\n",
    "\n",
    "with open(\"data/chain_of_thought_data_methods_logs.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(log_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
